These notes are even more scratch style notes.

SVG export and animation helpers

----------------------------------------

Unix: CentOS: How do you disable gnome-ssh-askpass for command-line use?

unset SSH_ASKPASS

http://kartzontech.blogspot.com/2011/04/how-to-disable-gnome-ssh-askpass.html

Nice automation script, try this one out:

cd ~/EddyWebViewer
git archive master | ssh mako0042@flute.cs.umn.edu \
  'rm -rf .www/EddyWebViewer
   mkdir  .www/EddyWebViewer
   cd     .www/EddyWebViewer
   tar -x
   chmod -R o+r .
   chmod o+x `find . -type d`'

----------------------------------------

Off topic:

http://blog.stackoverflow.com/2014/05/podcast-59-hes-one-of-those-science-ists/?cb=1

Well, maybe sites like Wikipedia and Stack Overflow need to take a
more pedagogical approach with new users, with special existing users
to give them the time and patience that they need.

https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Functions_and_function_scope/Strict_mode?redirectlocale=en-US&redirectslug=JavaScript%2FReference%2FFunctions_and_function_scope%2FStrict_mode

----------------------------------------

Code base plans

Alright, let's break up the renderer and implement it:

Almost finished, parts left TODO

* UI input interception

* 2D rendering

* clipGeometry()

* getClipBounds()

* inverseZRot(x, y) -> { x, y }

* rotateX, rotateY, rotateZ

* Wireframe render

Data I/O:

* Request data

* Write data

* Format detection

* Format handlers

--Avoid complicated OOP, this can really slow down compilers
and static implementations.  Try to stick to fast-style coding
when possible.

2D version: only one frontbuffer.  Bit-block images verbatim.

Highlight selected eddy.

Start rendering 1/4 down from top of screen, continue to bottom,
finish top 1/4.

Unit testing: JsUnit, QUnit

(Avoid the above frameworks, they do not maintain faithful
cross-browser compatibility.)

Discovery, design, component implementation/testing, composition.

Need to have table of acronyms and abbreviations

----------------------------------------

About box

If you are having problems with the web viewer, check if your browser
meets the minimum requirements and passes the browser CSS and Event
test suite and the JavaScript language test suite.  (Reference
renderings at 96 DPI.)  If it is possible to workaround a bug or
issue, send a patch to us and we will include it in the web viewer.

----------------------------------------

Questions answered.

Need two modes in the Eddy Web Viewer.

1. Watch tracks from day to day, see the tracks alpha fade in and fade
   out.  Follow an eddy, see how it changes until it vanishes.
   Boundary, track.

2. Visualize how the boundaries of the eddies change.

3. Click on an eddy, select it, get information, follow.

4. Focus in on a region, change color scale.

5. Advanced rendering attributes such as swirling eddies and hatches
   scale, probably not as important.

6. Like a database query, filter the eddies that are
   displayed.

7. Preferred format: whatever works fastest in the viewer.

8. Speed is critical.  Performance matters, monitor bandwidth
   requirements and limitations.

9. Web hosting?  Maybe move to Amazon Web Services, we'll figure that
   out later.

10. I'll need pointer locking and the "calibrate, please!" screen
    needs to be removed.

Important!  SSH data directory:
  /project/expeditions/eddies_project_data/web_viewer

keifenhe

Woodrow Keifenheim

Maybe I'll have to write a script from my CS account that remote
logins to.

So two modes: one to show eddies in motion, another to see eddies
static, then click on an eddy to get more information.  The first mode
is critical in importance, the second mode, not so much.

----------

Need to check quirksmode compatibility tables for mobile devices.

GLSL shaders?  Only for big machines.

http://earthobservatory.nasa.gov/Features/BlueMarble/?src=ve

Would streaming video allow SSH animations?

http://willus.com/author/streaming2.shtml

Here's how to track pinch events:

http://stackoverflow.com/questions/11183174/simplest-way-to-detect-a-pinch
https://developer.apple.com/library/safari/documentation/UserExperience/Reference/GestureEventClassReference/GestureEvent/GestureEvent.html

This is also useful:

http://quirksmode.org/dom/events/resize_mobile.html

----------

Performance

Important root of a tree of performance oriented links:

http://stackoverflow.com/questions/1246408/use-of-javascript-array-new-arrayn-declaration

Right, function calls are actually slow, if using aligned native data
is an option.

Great!  This will dramatically help me with performance-oriented
programming in this project: fast trigonometry:

http://jacksondunstan.com/articles/1190
http://en.wikipedia.org/wiki/Haxe

Turns out that lookup table trigonometry was not as fast as I thought
it would be.  It stabilizes performance when the browser's
trigonometry does not provide conistent performance, though.

Static variables incur significant overhead over local variables.

Copying variables is cheap in JavaScript.

Performance, performance...

http://stackoverflow.com/questions/18221571/haxe-compiled-code-peformance

Haxe might not be the best solution after all for compiling to
C++/C.  However, it will provide very good optimization features for
JavaScript programming, in addition to the Google Closure tools.

http://www.html5rocks.com/en/tutorials/canvas/performance/

So now what do I need to do?

1. Implement a simple JavaScript code inliner.

2. Set up a build process.

3. Create the kd-tree and quadtree implementations.

4. Get the C++ side working.

5. Get the data to a place for testing.

6. Finish the code modularization.

7. Use the cross-browser shim for requestAnimationFrame.

Slow canvas rendering?  Problem solved:

https://code.google.com/p/chromium/issues/detail?id=170021

Solution: break up a large texture into several small textures, each
no larger than 4096x4096 in size.  Paint each tile individually, then
use those as you need to.

http://stackoverflow.com/questions/12405471/why-does-drawimage-perform-slightly-noticeably-better-than-createpattern-in

Performance, performance...

http://www.webreference.com/programming/javascript/jkm3/index.html

Okay, let's try getting some performance data of my own.

Do function calls really slow things down?  No, unless the function is
block nested.  For some math functions, a lookup table function that
you provide may be faster, but that's only because the math functions
may not be implemented using fast math themselves.

Table access and object member access are essentially identical in
performance, at least in the simple cases.

Are global variables really slower than local variables?  No.
However, if I scale up the program to have a more crowded global
namespace, then this might actually be true.

Is property access really slower than direct local variable access?
No, but there are some exceptions.  In particular, you should not
access any properties that don't correspond to a real JavaScript
property, such as is the case for a function's arguments array.  It is
also probably a good idea to avoid using properties at the condition
check of a loop.

What about buffering?  I'll have to experiment with that, but luckily
it will be easy for my code to be written to make such experimentation
easy.

So where do the real slowdowns happen?  Excess assignment.  Be sure to
economize on assignment operations.

Creation of dictionary objects is also very expensive.  For all
practical purposes, creation of array objects is equally as expensive
as creating a dictionary object.  In other words, don't create
objects!  So this is why assigning values to an array is so slow!

Thus, avoid creating new objects via the new operator.

Moving variable declarations outside of a loop seems to have no effect
on performance.

In conclusion, best software development practices for structuring
large scale software should be able to scale well in JavaScript, even
on outdated interpreters.

Closure scoped variable performance?

http://stackoverflow.com/questions/9248963/javascript-why-the-access-to-closure-variable-might-be-slow

http://developer.nokia.com/community/wiki/JavaScript_Performance_Best_Practices

http://updates.html5rocks.com/2012/08/When-milliseconds-are-not-enough-performance-now
http://ejohn.org/blog/accuracy-of-javascript-time/
http://www.sitepoint.com/javascript-fast-string-concatenation/

https://developer.yahoo.com/performance/rules.html

Minimize HTTP requests.  That means stream data to the client from the
server in kd-tree order for the eddy tracks, and likewise stream the
SSH background as video data.  Use one large tracks file that is
random accessed like a memory mapped file.

http://www.ibm.com/developerworks/library/wa-aj-jsajaxperf/index.html

----------------------------------------

Here's they way to get rid of screen coordinate calibration screens:
just make sure there is no vertical scrollbar, and use the clientLeft
and clientTop properties.

http://stackoverflow.com/questions/2337795/screen-coordinates-of-a-element-via-javascript

http://www.quirksmode.org/dom/w3c_cssom.html#windowview

----------------------------------------

Here's how to draw graticule:

First, start out simple.  Looking at a globe equator-on-center,
parallels are straight lines and longitudinal lines are ellipses.
This can be drawn with ease.  Then, looking at the globe
pole-on-center, parallels are concentric circles around the pole, and
longitudinal lines are straight lines intersecting at the pole.

The next trick is to figure out how to render the graticule
orthograpically at positions in between these extremes.  When tilting
the globe from equator to pole, the 2D distance between the north and
south pole decrease from the pole separation to zero, exactly by the
cos() function for computing rotations.  Each circle, even when
deformed, always has its center at the core of the Earth, even in all
possible 2D orthographic projections.  Also, looking at the
longitudinal circles when tilting the globe without any rotation
around the pole, the maximum x extent of every longitudinal circle is
always the same.

* Parellels get stretched around the center from being a straight line
  equator on to being a circle pole-on.

* The x-width of parallels and longitudinal lines never changes.

* Longitudinal lines get progresively squashed when rotating.

* Totally squashed longitudinal lines are sheared up to the edge of
  the outer boundary circle of the globe when looking pole on.

Now the only trick is to compute the shear factor of the longitudinal
lines such that the correct effect will be achieved.

First compute the intended Z-axis transfer amount to the Y-axis.  This
will give you a length.  Shear factors operate by multiplying an X
coordinate by a shear factor and adding it to the Y coordinate.  So if
you know the X extend of a coordinate and you want a shear factor to
assign that X coordinate exactly a Y coordinate, the shear factor is
the target Y amount divided by the current X amount.  So here are the
equations.

The next challenge is to draw only the "front" lines of the graticule.
Again, this starts with simple observations.  Looking at a globe
equator-on, there is.

One challenge: How do you parameterize the sheared ellipses?  First
for shearing a circle, it turns out that sheared circles are indeed
ellipses, and the major axis of the sheared ellipse always runs
through the diagonals of the corresponding bounding rectangle.  I
don't know how to mathematically prove this.  I've only visually
verified it in a drawing program, so you're going to have to just
trust me on this one.

But for sheared ellipses, this fact does not hold.  However, if we
look at the problem in a different way, instead of squashing the
longitude lines horizontally first and then shearing vertically, we
could perform the transformations in the opposite order and still get
the same result, provided that we calculate the shearing correctly
with just a normal circle.  If so, we end up knowing the major axis of
the sheared circle.  Then when we horizontally squash the ellipse,
what we are essentially doing is changing the angle of any
non-vertical axis through the ellipse by a factor that we know how to
compute.  Thus, we can now successfully figure out what the angle of
squashed major axis must be.  The lengths of the axes can be figured
out trivially from knowledge at this problem solving step.

How do you determine which parts of latitude lines are on the front
and back of the sphere?  First determine if the entire latitude is on
the front or back side of the sphere.  If it is on the back, don't
render it.  This step is fairly easy.  The next step is to .

Longitude lines?  You need to determine the intersection of the
longitude line with the outline of the sphere.  The outline of the
sphere is a great circle line.  How do you parameterize this at
non-trivial rotations?

Think about the trivial case of the raytracing algorithms for
orthographic projection.  First you start with a screen coordinate.
asin() on the Y coordinate determines the latitude.  The longitude
depends on both the latitude and the X coordinate, since points on a
longitude at higher and lower latitudes are pulled tigher into the
north and south poles of the globe.  asin(x / cos(lat)) gives you the
longitude.  A great circle line is essentially a form of a straight
line on the globe.  When you view a great circle straight on in
orthographic projection, the projected line is also straight.

Thus, for starters, generate a great circle line by unprojecting a
straight line drawn on top of an orthographic projection of a sphere.
You will get an equation parametric to the projected line.  Remove the
parameter to get an implicit equation.

In the following equations, y = latitude, x = longitude.

    // Used to sample a point on the line.
    var stepper = (i / 36 - 0.5) * 2;
    var angle = 45 * DEG2RAD; // Angle of the great circle line
    var y = Math.asin(stepper * Math.sin(angle));
    var x = Math.asin(stepper * Math.cos(angle) / Math.cos(y)) *
      RAD2DEG / 180;

sin(y) = stepper * sin(angle)
stepper = sin(y) / sin(angle)
define y to be a known latitude
x = asin(sin(y) / sin(angle) * cos(angle) / cos(y))
x = asin(sin(y) / tan(angle) / cos(y))
x = asin(tan(y) / tan(angle))

y = known latitude
x = asin(tan(y) / tan(angle))
sin(x) = tan(y) / tan(angle)

More useful.  Most great circles cover all longitudes, but many great
circles do not cover all latitudes.
x = known longitude
y = atan(sin(x) * tan(angle))
tan(y) = sin(x) * tan(angle)

It becomes numerically unstable near the poles, but you also don't
need as much numeric stability near the poles, so it works out well.

tan(y) = sin(x) * sin(angle) / cos(angle)
y = atan2(sin(x) * sin(angle), cos(angle))

Perfect!  When a line is steep longitude-wise, that means its almost a
meridian, which means that it doesn't need as many samples on an
equirectangular map since it it almost just a vertical line.  In
between shallow and steep, a line gets a good number of samples.  The
atan2() function allows absolute extreme vertical to also be handled
gracefully, even with the same algorithm.  However, care will still
have to be taken for correct wraparound drawing.  To shift the great
circle pole away from the prime meridian, just add or subtract the
desired longitude.

Wait, not quite perfect.  How about use a parameterization along the
distance of the great circle line instead?

sin(y) / cos(y) = sin(x) * sin(angle) / cos(angle)
sin(y) / sin(x) = cos(y) * sin(angle) / cos(angle)
sin(y) / sin(x) = cos(y) / cos(angle) * sin(angle)
sin(y) * sin(x) = cos(y) / cos(angle) * sin(angle)

Those equations are elegant, but numerically instable.  Let's see if
we can do better.

x = asin(sin(y) / cos(y) * cos(angle) / sin(angle))
x = asin(sin(y) / sin(angle) * cos(angle) / cos(y))
x = asin(cos(angle) * sin(y) / (sin(angle) * cos(y)))

sin(y) * cos(angle) = 1/2 * sin(y + angle) + sin(y - angle)
sin(angle) * cos(y) = 1/2 * sin(y + angle) - sin(y - angle)

cos(angle) * sin(y) / (sin(angle) * cos(y)) =
  (sin(y + angle) + sin(y - angle)) / (sin(y + angle) - sin(y - angle))

sin(x) = o / h

o = sin(y + angle) + sin(y - angle)
h = sin(y + angle) - sin(y - angle)
a = sqrt(h^2 - o^2)

Numerically stable?  Check which of o or a are greater than each
other.  If steep, then invert and fix afterward.

x = asin(cos(angle) * sin(y) / (sin(angle) * cos(y)))
sin(x) = cos(angle) * sin(y) / (sin(angle) * cos(y))
sin(angle) * sin(x) * cos(y) = cos(angle) * sin(y)

----------------------------------------

Great advice on getting ellipses to render with constant line width:

http://stackoverflow.com/questions/2172798/how-to-draw-an-oval-in-html5-canvas

Clipping does not need to be performed manually, since it will be done
by the underlying canvas implementation as needed.

This leaves things up to tree lookup.

Drawing clipped polygons.  For each polygon, first determine which
clock-winding direction corresponds to the closed polygon.  Then use
clock-winding rule to determine interior of polygon.  Once the
interior of the polygon has been found, draw with the two points just
off the screen and add vertices for each screen coordinate located
within the polygon.

Drawing other projections:

1. Initialize bitmap backbuffers via unprojection tracing from the
   target buffer pixels.

2. While rendering any features, transform the point by the current
   projection.

Always store relatively large render caches as tiled image buffers, up
to a maximum size.  Must keep this small in order to preserve
compatibility with older browsers.

Want to link zoom factor and field of view?  Here's how.

Calculate the radius of the projected sphere.  Field of view.

Map orthographic to perspective.

1. Computer disp_rad.

2. Raytrace a point of disp_rad out to the plane.

3. You'll get something with a radius too large.

Try working backwards.

1. Raytrace the edge of the globe.

2. You'll get a screen position and therefore the scale.

x / (r + d) = x_pix / f

Wait, but there are two ways of doing this!

At orthographic edge: Best for small fields of view entire Earth
visible.
At visible edge: less surprises at high zoom levels.

So I need to be able to choose between the two.

Detecting browser capabilities...
[if canvas is found]
Benchmarking rendering performance...
Benchmark complete.  Optimal rendering parameters selected.
Downloading initial dataset...
Download complete.

Pre-load an image?  Just use JavaScript and HTML 5 image loading
like so?

http://www.htmlgoodies.com/tutorials/web_graphics/article.php/3480001

Great!  Image flipping, pre-render and then flip at high speed.

http://www.htmlgoodies.com/tutorials/web_graphics/article.php/3479941

Want to make a link open in a different window?

Use <a href="..." target="resource window"></a> as one method.

----------

HTML validity checklist:

* Verify void tags end with " />"

* Run all documents through the CSS and markup validators.

* Verify all inline scripts have polyglot wrapping markers.

* Verify all documents use IE6 CSS fallbacks.

* Verify all CSS layouts have IE6 CSS fallback scripts.

* Do not use the SVG loading image by default.

* Preload GUI icon images.

* Check that all the "alt" tags have reasonable text.  Either use
  brackets or periods to delimit the end of identifiers.

* Check all webpages in Lynx and w3m.

JavaScript checklist:

* Keep the identifiers in camelCase.

* Parse text fields more gracefully.

* Always perform error checking whenever applicable.

* Use parseInt() to parse user input numbers.

* Add "use strict" to all production code and test.

* Avoid over-object-orientation and try to test code quickly after it
  is written.

* Benchmark the memory consumption of having a certain number of
  JavaScript objects around, gauge "stack" variables and garbage
  collector leftover waste.

* Check for "~~" and replace with "0|".

* Verify that all HTML Canvas operations are structured so as to be
  supported on all conforming browsers.

* Always use parentheses with typeof operator?  `delete' operator too?

* Always use document.x() and window.x() rather than the global
  namespace name.

----------

Build the packed quadtrees:

1. Sort all the coordinates.
2. Scan through the coordinates in order.
3. Keep track of coordinate spacing.
4. When large batches of similarly spaced coordinates
   are found, bundle them into a packed structure.  Pad out
   any uneven space with interpolation.
5. Build the kd-tree on the packed coordinates.
6. Build linear interpolation reduction trees on top of the
   kd-tree.
7. Provide a server-side image generator to assist in sending
   pregenerated images straight to the client for video display.

It turns out that no sparse array magic will be needed on the SSH
data.  Just process it identical to how it is done in Google Earth.

----------

Need new CSS GUI test suites:

Box resize check

Mouse wheel check

CSS compatibility: Do not use periods in element IDs.

Fast and efficient way to get the current time in milliseconds:

if (!Date.now) {
  Date.now = function now() {
    return new Date.getTime();
  };
}

Date.now;

https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Date/now

----------------------------------------

Efficiently encode the Sea Surface Height

Up to eight digits after the decimal point.
Up to three digits before the decimal point.

96% +- 31.999999

1 11111 111111111111111111

31.00005

// Run through each number.
// If it exceeds +- 32, then clamp it to the maximum.
// Or set it to NaN (-32).  Need a good way to encode this with JPEG.
// Shift left by 2^18.
// Convert to integer for fixed point.
// Write three low order bytes, one at a time, into target byte order.
// Write out image.
// Send it through JPEG compressor.
// Separate PNG compressed info map.

----------------------------------------

Get an older version of Opera for compatibility testing:

http://arc.opera.com/pub/opera/linux/754/final/en/i386/static/

Great high performance JavaScript CSV parser:

https://code.google.com/p/jquery-csv/

----------------------------------------

So what do I need to do in order to finish up the viewer?

* Implement some render layers.  Do some testing.

* Clean up the compatibility code.

* Finish the slim GUI.

Should center be a projection property?

What is a projection property?

Affline transformations have nothing to do with the projection.

Questions to ask Woodrow and James:

* Data precision?  32-bit floating point SSH.  24-bit fixed point.
  +/- 32 before the decimal, after the decimal.  JPEG compression,
  video compression.

* Do you want your SSH pixels nice and square or do you prefer
  bilinear interpolation smoothing?

* Resolution?  720x1440 for the current SSH data.

* How do the smallest size eddy tracks compare with the SSH
  resolution?

* The Sea Surface Height data measures from the international date
  line, not the prime meridian?

* Do you want the dates to appear hyphenless in the GUI?

* The main cause of slowness in track rendering appears to be
  differences in how efficient browsers are when being commanded to
  draw a line on the canvas.  One way to stabilize performance across
  browsers is to do all line rasterization in JavaScript and use
  putImageData(), as is being done with the raytracing renderers.
  Question which I already know the answer to: How do you draw a line
  without dividing to compute the slope?

* Any seasonal variations observed with the eddies?

* Browser testing?  Emulators of mobile devices.

* What did Hung mean by "slow"?

* NOT using SVG.  SVG DOM performance is said to be very poor when
  working with a large number of nodes.  This will especially be true
  if each eddy DOM object has an event listener attached to it.
  Memory leaks could also become a problem.  However, I haven't tested
  with SVG on this many datapoints, so I don't have specific evidence
  for these assertions yet.

* Web hosting?  Where should the site officially reside?

* JavaScript development in the labs: node.js

* Features vs. solidness of design.

* Visualization?  Highlight track datapoints how?

* What about the other viewers people are using?  Hung's viewer too
  slow?

* License notices?  Code included from other projects include them.

* What's with that computer next to this one that seems not to
  work?

Things to say:

* Above average cross-browser compatibility and performance.
  Great new slim GUI, cothreading...

* Need to say /competitively exceed/.  Performance like jsperf
  and Browserscope.  Not mediocre like D3.js.

* C to JavaScript translator.

* In case the whole web app thing cannot deliver that great of
  performance, we'll have a native backup.

* Plus, I'll be using all of my best codebase tricks in the code.

* Draw a crosshair at the center?

Things for me to do:

* I need to be make sure I implement multiple rendering mechanisms.

* It seems that loading the large JSON data is okay.  That means
  that I should be able to safely move onto building the kd-trees.

* Number of required experiments in rendering mechanisms:

* Tracks: full loading single image (composite image tiles) render,
  partial loading via XMLHttpRequest seeking, caching, w/wo kd-tree.

* SSH:  single load single render, reduction tiles.

* Best way to specify which code paths to use?  Just use class
  properties, maybe possibly use a setter function.

* Consolidate compatibility code.

* Multiple color schemes on the SSH RenderLayer.

* Interlaced raytracer.

HTTP 1.1 Specification for XMLHttpRequest headers:

http://www.w3.org/Protocols/rfc2616/rfc2616.html

Answers:

* Format of the dates: with/without dashes/hyphens, either way,
  whatever looks better.

* SSH at international date line: yes, you may need to shift so that
  it looks more interesting to other people.

* License notices: just open-source, like MIT license.  Make sure to
  say your name that you made it, though.

* Web hosting: Look on your own, check out Amazon Web Services, Google
  App Engine, see what works the best from home.  Then maybe go into
  to ring they have downstairs and go through MSI, the point is to
  find out what works best from home.  On your own, try to look for
  what works well from home.  Like you're making a proposal.

* SSH resolution?  Will probably stay at 1440x720 for the whole
  project.  Not entirely necessary, an experienced person would be
  able to look at it and just tell if that's an eddy or not.

* JPEG compression?  Shouldn't be an issue to limit down the precision
  of the SSH datapoints.

* Eddies that twist around across only a few pixels?  Maybe hide them
  at the global scale, show them when you zoom in.

* No seasonal variations observed with eddies, except that the
  increasing size of the ice caps can limit the oceanspace available
  to the eddies.

* Node.js installed on MSI?  Go ask help.msi.umn.edu, cc both James
  and Kumar, tell them you're working on this open-source project,
  make sure everything is cc on they're behalf so that that can
  intervene and answer for your.  We're the largest user of MSI so
  they will be friendly.

* We should try to get it to a state for other users to just get up
  and on the software, and see what features may be useful.

* Don't concentrate too much on the mobile, might not get the same
  experience as on desktop.

* The SSH data isn't entirely necessary.  Maybe don't need to load it
  all.  So animation can be done with the tracks alone.

To Woody:

* Please store the length of the tracks within the tracks somehow.

* Maybe the rendering engine should precompute and store the lengths.

For me:

* I need to allow generating information on the URL when the user
  changes the projection, view, etc.

* Need to alpha in/out on the tracks.

* Only load the data when needed.

JPEG Quality levels to consider:

... just use the default.  And don't even think about JPEG 2000.

http://blog.codinghorror.com/beyond-jpeg/
http://blogs.loc.gov/digitalpreservation/2013/01/is-jpeg-2000-a-preservation-risk/

Need more consistent performance between Firefox and Chrome?  Use a
JavaScript line rasterizer.

http://en.wikipedia.org/wiki/Bresenham%27s_line_algorithm

NOTE: You cannot store arbitrary data in a PNG 32-bit image since it
will not be preserved due to premultiplied alpha.

Provide control over manual/automatic sea surface height scaling.

First thing to ask James next time:

So how many other eddy viewers are there?

Want a nice, translucent background on a CSS element?

http://robertnyman.com/2010/01/11/css-background-transparency-without-affecting-child-elements-through-rgba-and-filters/

When finished, change all CSS measurements to metric, please!

Wow!  Here's another way to include images inline:

http://css-tricks.com/data-uris/
http://css-tricks.com/32766/
http://css-tricks.com/snippets/htaccess/active-gzip-compression/

Unfortunately, IE 5-7 does not support this.

If the user's browser doesn't support this, the data will have to be
routed back to the user via the server.  Luckily, most people do not
use browsers that are too old to have support, so this will not impose
undue burden on the server.

Great!  This is even better to finish things off:

http://www.xarg.org/2010/03/generate-client-side-png-files-using-javascript/
http://www.xarg.org/download/pnglib.js

Plus, it's even reported to have faster per-pixel manipulation than
HTML Canvas!  Execpt at large sizes...

Take note: For better speed, use brower's base64encode:

this.getBase64 = function() {
return window.btoa(this.getDump());
}

Plus, this also has the added advantage of an efficient 8-bit image
copying mechanism.  So you could generate an image 8-bit inline and
work with that with this library.  But... read from an 8-bit
downloaded image?  Not so much.

I should improve the library so that it includes fast single pass
stream encoding.  Multiple loops incur extra overhead.

----------------------------------------

Can you check the loading progress of an image created via new
Image()?  Not quite... sort of, but only with modern browsers.

http://stackoverflow.com/questions/14218607/javascript-loading-progress-of-an-image

----------------------------------------

Need a coding scratch space?  Got one right here.

Iterations to timeout algorithm:

/* Dynamically determine a goal number of iterations to run in order to
   reach the target timeout, based off of the number of iterations that
   could be performed in the previous cothread duration.  */

/* The main benefit of this cothreading mechanism is that it avoids
   expensive calls to Date.now() during the inner loop.  */

var timeout = this.timeout;
var lastElapTime = this.lastElapTime;
var lastNumIters = this.lastNumIters
var numIters = lastNumIters * timeout / lastElapTime;
var timeoutIter = this.i + numIters;

lastTime = Date.now();

for (; i < timeoutIter && condition; i++) {
}

lastElapTime = Date.now() - lastTime;
lastNumIters = numIters;

/* The above algorithm can also be nested within a loop that calls
   Date.now() on every iteration.  */

Buffering data:
loadData() handles this.

Cothread dispatcher:

Note that it is possible to use an array of cothreads that still have
work to do and only call those cothreads.  For simplicity, however,
cothreads are a always called to continueCT() until there is no work
left to do.  Only event handlers call start().

cumStatus = CothreadStatus.FINISHED;
renderReady = setViewport();
addStatus = loadData.continueCT(maybeAddToBuffer);
if (addStatus) cumStatus = addStatus;
if (renderReady)
  render.continueCT();

if (cumStatus != CothreadStatus.FINISHED)
  return setTimeout(browserTime);

kd-tree or heap?  That is the question.

Let's try looking at what can be done with a heap.

I.  Time comes first.  You have to search the timeframe range before
searching the spatial range.

Advantage: Can download eddies at nearest timeframe first.  Then
eddies are spatially downloaded across the globe within one time
frame.

Since the data is sorted, it can still be binary searched.  Thus, it
can be approached similar to a kd-tree traversal.  Good, this will be
interesting.  So this is a hybrid between a kd-tree and a sorted
array.

Not really too nice.  Then again, each eddy from a different timefrane
needs to be shaded differently.

Try this one out!  Can you use a global kd tree partition but locally
sort points to appear in chronological order?  If so, then efficient
time slicing should be possible without having to load all of the
data.  So this is where chunking is needed, but I still don't quite
get how to optimize this case.

Yes, it is possible, but it is very non-trivial.  Start with an
assumption.  A sorted array is a binary search tree.  Unfortunately,
it does not have a regular heap structure.

The idea is to just do a kd-tree traversal once for the 2d range and
then reuse the kd-tree across multiple dates in iterated order.

How about this way: build the big kd-tree dynamically, but load the
data in chronological order.  Yes, that's what I was getting at.  If
you know the number of data points, you know what the tree structure
must be.

The only way to do it your way would be to use "bogus points", or a
selection of top-level kd-tree notes that absolutely must be
downloaded.  That way, there is a high-level partition that is always
consistent.  Going further down from here, disjoint trees can be
searched individually, with significantly less points to search.
Low-level trees can be merged for faster range searcing.

Chrono download is still an issue.  Okay, here we go.  The data will
be broken up into fixed size chunks of an octree.  Further 2D
subdivision is handled via a kd-tree.  This means that multiple kd
trees will be downloaded at runtime, and consolidation must happen at
runtime.  What about removing decached data?  That requires kd-tree
deconstruction.  In other words, if kd-tree construction and
deconstruction becomes a bottleneck, then it should be skipped
altogether.

Okay, the decision is made.  No kd tree deconstruction.  Use a
recursive quad-tree structure and time framing.  I've looked at the
data myself and it only looks sparse over the land.  This can be
handled easily though by marking entire high level boxes as empty.
Points will be sorted in on a case-by-case basis.

Yes, this means multiple tree traversals will have to be made.  Or, by
only using a single quadtree structure, only one tree traversal needs
to be made.

Yet another great way to put together this web app.  I can use web
workers to help with the threaded rendering process.  The catch: this
web app won't benefit from web workers unless the browser also
supports data transfers.  Otherwise, passing objects and data will be
way too inefficient to be practical.

Things are looking good.  The HTML video element provides enough
control over playback for me to just superimpose a video element for
the SSH data.  In fact, I could retrieve all the data I need from a
video element, both for <canvas> and WebGL rendering.

Could this be the solution to the problem of Internet Explorer giving
me extra space underneath the iconBtns?

http://bonrouge.com/br.php?page=faq#img-gap
http://www.sitepoint.com/forums/showthread.php?249148-IE-puts-extra-space-at-bottom-of-image-in-a-div

That will do it.  But wow, that sure is a strange way to do it, very
non-CSS like in order to get the IE-style box model to work.

NOTE: Object oriented code has a tendency to be slower.

----------------------------------------

Useful cross-browser links:

http://www.cinsoft.net/mylib.html
https://github.com/rassie/jessie
http://michaux.ca/articles/feature-detection-state-of-the-art-browser-scripting
http://www.fortybelow.ca/Projects/JavaScript/Utils/

And for simulating colorblind vision:

http://vischeck.com/

----------------------------------------

So how will I know "when I'm done"?  These are the few remaining
criteria:

Pre-Genesis:

* Solidify the TracksLayer and SSHLayer implementations.

----

* Implement the main loop.

* Load the SSH data as encoded images or as a video element.

* Progressively load the tracks data and tree traversal for potential
  visibility rendering.

* Full compatibility analysis.

* Fully documented code.

* Full developer documentation.

* Complete user documentation.

* Full and streamlined GUI.

* Full site design.

* 3D acceleration.

* Clean codebase.

* Smooth view transitions between multiple projections.

* Test cases.

* Fast, fast, fast!

Additional features:

* Native implementation

* Web Workers

Google site:

https://sites.google.com/a/umn.edu/mako-eddy-web-viewer/

Performance optimization: Go through my code and change all constants
to #define and likewise for inline functions.

----------------------------------------

Gotta make multiple versions:

csvtotga: convert csv to 32-bit floats in a 32-bit TGA, with the
  right transformations applied
tgafmt: format to fixed point numbers for web viewer

tgatoptga: convert to jpg with a pre-applied color palette
tgartga: render a tga with a projection

... or just use a series of options right inside the program

... drives me crazy.  just use full memory buffers for the pipeline.

Web Viewer Friendly Eddy Format:

- Series of fixed-width fields

[f1],[f2],[f3],...,[fn]

First field: [ date_index, num_eddies ]

num_eddies fields follows

Each eddy field is like this:

[ eddy_type, eddy_id, latitude, longitude, prev_eddy, next_eddy ]

eddy_type is 0 for cyclonic, 1 for acyclonic.  prev_eddy is the number
of records backwards in the file to scan to get the previous eddy from
the current eddy.  If zero, then this is the first eddy in the track.
Likewise, next_eddy is the number of records forward to scan to get
the next eddy in the track.  If zero, then this is the last eddy in
the track.

Following num_eddies is either another "first field" or the end
of the file.

Wait, but then that's not full random access...

Oh yeah, download all the date index entries at the start of the
file.  Then the rest of the file is random accesss.

File starts with a list of dates, each a fixed with field...

Then follows the eddies in a contiguous array.

* Avoid pointers in the code to decrease load on the garbage
  collector reference counting mechanism.  Use indexes when
  possible instead.

Inside the quadtree, there is an eddy index and an indicator of
cyclonic/anticyclonic.  I know, it's a pain to keep track of so
many objects, but this is how things must start.  To mitigate
this, only load in eddies that are needed.

To make things simple, just implement both a kd-tree and a quad-tree.
Summary of differences.  A kd-tree has better memory characteristics
(O(n)) but worse lookup time (O(lg n)), but a quad-tree has better
lookup time (O(1)) but worse memory characteristics (number of cells +
number of elements).

So here's the challlenge: What is the threshold where a kd-tree and a
quad-tree break even?  You need to compare just lookup time: a kd-tree
obviously wins all when it comes to memory cost.

If memory is at a premium, then use a kd-tree.  For large sizes, a
kd-tree will obviously benefit from not storing a huge cell bucket
structure.  Otherwise, if there is not much memory demand (small
number of elements), then use a quad-tree.  However, a kd-tree
competitively matches the speed of a quad-tree when there are not many
elements.  Additionally, a quad-tree may have issues with exceeding
the size of the CPU cache.

I guess the decision is clear then... kd-trees are the invariant
winner.  Plus, even if I did go with quad-trees, I'd have to bucket
into date blocks anyways, each of which would need its own quad-tree,
and iterating through common dates would necessarily have to iterate
through multiple date blocks, so segmented kd-trees aren't all that
bad.  One problem with kd-trees is that it would take time to build a
kd-tree client-side, but if the kd-tree is only loaded in server
pre-built blocks, then this is not an issue.  Here's where my blocking
structures come into play.

Grouping multiple nearby dates into date blocks really helps the
algorithm.  I think that was the only missing thought from my previous
plans.

The question, then, is how big is the block size?  64 KB, how about
that.  Doesn't give the best experience for 56 kbps moden users, but
should be good enough.  Only about 250 tracks/block?  No, that's too
small.  That's the size that supposed to be in only one bucket.  Were
a quad-tree to be used instead, how many cells should there be in one
timeframe bucket?  64 x 128 = 8192.  There will be 2048000
tracks/block.  2048000 * 262 bytes = 511 MB?  That's way too big,
though.  Okay, it's a deal: 64 KB/block.

Wow, another optimization: Rather than nesting arrays, just line up a
fixed number of numbers into one big array.  Maybe?  Or maybe that's
not enough blocking to be a machine optimal block size.

Don't use one big mesh array.  Use nested arrays: The overhead will be
minimal, and dynamically adding and removing elements will be faster.

Last argument for using a top-level kd-tree.  Advantage: Gives a
top-level three-dimensional kd-tree for latitude, longitude, and date.
This gives a good even partitioning of the overall large-scale domain.
Lower in the kd-tree when there is only one discreet date, the kd-tree
downgrades to a series of 2D kd-trees that can be downloaded
separately.  bsearch-style tree storage guarantees that these 2D
kd-trees will be contiguous and uninterrupted in memory.
Disadvantage: Even when storing with a bsearch-style tree, there are
no guarantees that any points of any dimension will be stored in
order.  Here's how it works.  Consider the 2D case.  You have a
kd-tree with one X split.  Then in one of the X cells, you have a Y
split.  Now consider any X ordering of points in the two Y cells.
When the tree is stored in memory bsearch-style, one of these entire Y
cells is going to have to come before the other, even though both sets
of X ordered points are the same.  Thus, the kd-tree does not store
data fully ordered in any one dimension, but rather in "kd-tree"
order.

Okay, I've think I've got it for tracks rendering:

kd-tree sort lats and lons of eddies on the same date.  Store the tree
in bsearch order.  Then sort all the dates in ascending order.  The
superstructure will be stored in this order.

Render a track:

For each date in the render visibility range:
  Do a potential visibility traversal of the kd-tree to determine the
    list of points to be rendered.
  Assign opacities based off of the date index.
  Render the point, if necessary.

Next, render the lines to connect the points:
  Sort the list of points to be rendered by index.
  Note that when rendering the lines, the first point in the line will
    always have the lowest index.  Also note that we only need to traverse
    the linked list of render points in forward order for drawing visible
    lines.  Backward-order traversal is only used to smooth the direction
    arrow when drawing only one timeframe.
  Start connecting lines on points, going up one index at a time in the
    list until there are no more lines left to be rendered.

Viable idea for singly linked lists: "next" eddy indexes never point
backwards in time, so if you do store a "next" index that points
backwards in time, that marks the end of the list, and the backwards
pointer actually points to the eddy that corresponds to the start of
the list.  So singly-linked list storage is economic for transmitting
the data over the Internet.  For the viewer, it might convenient to
construct the backwards pointers, but this is optional and up to the
choice of the implementer of the viewer.

No, I got it wrong this whole time.  You only need to kd-tree traverse
the first date index to be rendered.  Then you can get the following
points via the "next" pointers, no tree traversal involved.  You can
determine the date index from the pointer.  If two points of a line
are out of range, then don't render the line.  Stop traversing when
you exceed the last date index to render.

Wrong again.  Must always kd-tree traverse current timeframe points,
otherwise you'll short-count the number of visible tracks.

* You need "prev" pointers so that you can draw the escaping lines
  from visible tracks.

Okay, I think I've got it.  I can divide up the rendering process into
speed classes.

Class 0: For no visibility testing, just do forward traversal starting
from the first eddy of a track.

Class I: PVS traverse only the current timeframe.  Determine the past
and future tracks to render using only the "next" and "prev" pointers.

Class II: PVS traverse the first visible and the current timeframe.
Use only the "next" pointers to determine the tracks to render.

Class III: PVS traverse all visible timeframes.  Traverse only one
"next" pointer link to render one track line.  Only render a track
line from traversing one "prev" pointer link if the previous eddy is
outside of the visible render area.  (This only works well if visible
boundary checking is fast, i.e. no obviously curved boundary lines.)

One problem: These visibility testers miss lines where both endpoints
are on the outside of a cell.  The only computationally fast solution
to this problem is to "paint" the top-most intermediary kd-tree cell
which a line passes through but doesn't contain either of the two
endpoints.  This comes at the expensive of greater memory demand,
though, and is likely to have no practical advantage at the lowest
levels of the kd-tree.

Such additional points can be tagged as "virtual" points when added
into the tree.

How do you add them to the tree?  You can't add them to the tree until
one version of the tree has been already built.  Where do you add
them?  At the dividing node within a cell.  What levels do you not
want to do this at?  That's a hard question.  Let's look at it this
way.  We want less than 1% of the points in the kd-tree to result in
adding virtual intermediary points.  Thus, this is only performed at
the the top few levels of the tree.  lg(n / 100) defines the number of
top tree levels to use.  Overall, the memory and runtime
characteristics of this are not all that favorable, so we'll have to
go without using it.

An entirely aside solution to these problems is to store the data
track-wise, with the tracks sorted by there geographic size (maximum
distance between any two points in the track).  Then each track is
assigned a bounding box.  Then a kd-tree is built on top of this sort.
This solves all the problems with the painting intermediary points of
large scale tracks, but the major problem with this mechanism is that
does not economize interactive downloading.

It might actually be a good thing to not render very large scale lines
that cross across a small region you are trying to look at, though.
It might also be the case that the eddy tracks do not practically
behave like this, so it makes sense to just go with the algorithms
given above.
